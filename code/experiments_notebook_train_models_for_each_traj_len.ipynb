{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "from utils import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from experiments import *\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hoc_num = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "traj_len = 2\n",
    "\n",
    "x, y, student_ids = load_data_will_student_solve_next_problem_traj_len(hoc_num, only_traj_len=traj_len, y_is_seq=False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model created. Ready to be loaded. \n"
     ]
    }
   ],
   "source": [
    "model_id = \"predict_next_prob_binary_two_layer_traj_len_{}\".format(traj_len)\n",
    "n_timesteps = x_train.shape[1]\n",
    "n_hidden = 64\n",
    "n_inputdim = x_train.shape[2]\n",
    "n_classes = 2\n",
    "architecture = 'two_layer_lstm_predict_binary'\n",
    "check_model_exists_or_create_new(model_id, n_timesteps, n_inputdim, n_hidden, n_classes, architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3176  | total loss: \u001b[1m\u001b[32m0.18933\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 008 | loss: 0.18933 - acc: 0.9413 | val_loss: 0.18637 - val_acc: 0.9404 -- iter: 25351/25351\n",
      "Training Step: 3176  | total loss: \u001b[1m\u001b[32m0.18933\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 008 | loss: 0.18933 - acc: 0.9413 | val_loss: 0.18637 - val_acc: 0.9404 -- iter: 25351/25351\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/Dropout.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/Dropout.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.940748366941\t Test acc: 0.941853035144\n"
     ]
    }
   ],
   "source": [
    "graph_to_use = tf.Graph()\n",
    "with graph_to_use.as_default():\n",
    "    model = load_model(model_id, load_checkpoint=False, is_training=True)\n",
    "    date_time_string = datetime.datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    run_id = \"{}_{}\".format(model_id, date_time_string)\n",
    "    model.fit(x_train, y_train, n_epoch=8, validation_set=0.1, show_metric=True, snapshot_step=100, run_id=run_id)\n",
    "    pred_train = np.argmax(model.predict(x_train), axis=1)\n",
    "    pred_test = np.argmax(model.predict(x_test), axis=1)\n",
    "    train_acc = accuracy_score(pred_train, np.argmax(y_train, axis=1))\n",
    "    test_acc = accuracy_score(pred_test,  np.argmax(y_test, axis=1))\n",
    "    print (\"Train acc: {}\\t Test acc: {}\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_accs, test_accs = [], []\n",
    "train_accs.append(train_acc)\n",
    "test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.43852\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 008 | loss: 0.43852 - acc: 0.8012 | val_loss: 0.44834 - val_acc: 0.8063 -- iter: 1713/1713\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.43852\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 008 | loss: 0.43852 - acc: 0.8012 | val_loss: 0.44834 - val_acc: 0.8063 -- iter: 1713/1713\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/Dropout.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/Dropout.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/Dropout.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n",
      "WARNING:tensorflow:Error encountered when serializing layer_tensor/lstm_1.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef.\n",
      "'list' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.830882352941\t Test acc: 0.844339622642\n"
     ]
    }
   ],
   "source": [
    "for traj_len in range(3,11):\n",
    "    x, y, student_ids = load_data_will_student_solve_next_problem_traj_len(hoc_num, only_traj_len=traj_len, y_is_seq=False)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "    model_id = \"predict_next_prob_binary_two_layer_traj_len_{}\".format(traj_len)\n",
    "    n_timesteps = x_train.shape[1]\n",
    "    n_hidden = 64\n",
    "    n_inputdim = x_train.shape[2]\n",
    "    n_classes = 2\n",
    "    architecture = 'two_layer_lstm_predict_binary'\n",
    "    check_model_exists_or_create_new(model_id, n_timesteps, n_inputdim, n_hidden, n_classes, architecture)\n",
    "    graph_to_use = tf.Graph()\n",
    "    with graph_to_use.as_default():\n",
    "        model = load_model(model_id, load_checkpoint=False, is_training=True)\n",
    "        date_time_string = datetime.datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "        run_id = \"{}_{}\".format(model_id, date_time_string)\n",
    "        model.fit(x_train, y_train, n_epoch=8, validation_set=0.1, show_metric=True, snapshot_step=100, run_id=run_id)\n",
    "        pred_train = np.argmax(model.predict(x_train), axis=1)\n",
    "        pred_test = np.argmax(model.predict(x_test), axis=1)\n",
    "        train_acc = accuracy_score(pred_train, np.argmax(y_train, axis=1))\n",
    "        test_acc = accuracy_score(pred_test,  np.argmax(y_test, axis=1))\n",
    "        print (\"Train acc: {}\\t Test acc: {}\".format(train_acc, test_acc))\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94074836694120989, 0.90721220527045765, 0.89100635239050485, 0.87208936438011331, 0.86531210724759111, 0.86058201058201056, 0.83923050498110618, 0.82007496876301544, 0.83088235294117652]\n",
      "[0.94185303514376995, 0.90018714909544606, 0.88476953907815636, 0.85855728429985856, 0.85687382297551784, 0.82422802850356292, 0.80246913580246915, 0.81273408239700373, 0.84433962264150941]\n"
     ]
    }
   ],
   "source": [
    "print train_accs\n",
    "print test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
